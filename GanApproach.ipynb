{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import torchvision.datasets\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import T_co\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_root = \"Data/train\"\n",
    "images_only_root = \"Data/train_semi_supervised\"\n",
    "test_root = \"Data/test\"\n",
    "train_csv = \"Data/train.csv\"\n",
    "epsilon = np.finfo(float).eps\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 4\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def process_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\tdf = df.set_index('id')\n",
    "\tannotations = df.groupby(['id'])['annotation'].transform(\n",
    "\t\tlambda x: ' '.join(x)).drop_duplicates()\n",
    "\ttypes = df.groupby(['id'])['cell_type'].unique()\n",
    "\treturn annotations.to_frame().join(types)\n",
    "\n",
    "def reconstruct_annotations_image(annotations, height, width) -> np.array:\n",
    "\tannotations = np.array(annotations.split(\" \")).astype(int)\n",
    "\timage = np.zeros(shape=(height * width))\n",
    "\tfor i in np.arange(0, len(annotations), 2):\n",
    "\t\tbegin = annotations[i]\n",
    "\t\tlength = annotations[i+1] - 1\n",
    "\t\timage[begin: begin+length] = 1\n",
    "\treturn image.reshape(height, width)\n",
    "\n",
    "def ToTensor(sample):\n",
    "\timage, ann_image = sample['image'], sample['annotation']\n",
    "\t# swap color axis because\n",
    "\t# numpy image: H x W x C\n",
    "\t# torch image: C x H x W\n",
    "\timage = image.transpose((2, 0, 1))\n",
    "\tann_image = ann_image.transpose((2, 0, 1))\n",
    "\treturn {'image': torch.from_numpy(image),\n",
    "\t\t\t'annotation': torch.from_numpy(ann_image)}\n",
    "\n",
    "class RandomChoiceTransform(torch.nn.Module):\n",
    "\tdef __init__(self, transforms):\n",
    "\t   super().__init__()\n",
    "\t   self.transforms = transforms\n",
    "\n",
    "\tdef __call__(self, imgs):\n",
    "\t\tt = random.choice(self.transforms)\n",
    "\t\treturn [t(img) for img in imgs]\n",
    "\n",
    "class CellsAnnTrainDataSet(Dataset):\n",
    "\tdef __init__(self, root_dir, csv_file, color_transform=None, shape_transform=None):\n",
    "\t\tself.df = None\n",
    "\t\tdf = pd.read_csv(csv_file)\n",
    "\t\tself.df = process_df(df)\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.color_transform = color_transform\n",
    "\t\tself.shape_transform = shape_transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.df)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tif torch.is_tensor(index):\n",
    "\t\t\tindex = index.tolist()\n",
    "\t\timage_id = self.df.iloc[index].name\n",
    "\t\timage_name = f\"{image_id}.png\"\n",
    "\t\timage_path = os.path.join(self.root_dir, image_name)\n",
    "\t\timage = plt.imread(image_path)[:,:,np.newaxis]\n",
    "\t\twidth, height = image.shape[:2]\n",
    "\t\tannotations = self.df.iloc[index]['annotation']\n",
    "\t\tann_image = reconstruct_annotations_image(annotations, width, height)[:,:,np.newaxis]\n",
    "\t\tif self.color_transform is not None:\n",
    "\t\t\timage = self.color_transform(image)\n",
    "\t\tif self.shape_transform is not None:\n",
    "\t\t\timage = self.shape_transform(image)\n",
    "\t\t\tann_image = self.shape_transform(ann_image)\n",
    "\t\treturn ToTensor({'image': image, \"annotation\": ann_image})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "image_w_ann_data = CellsAnnTrainDataSet(annot_root, train_csv)\n",
    "image_only_data = torchvision.datasets.ImageFolder(images_only_root, transform=[transforms.ToTensor()])\n",
    "images_w_ann_loader = torch.utils.data.DataLoader(image_w_ann_data, batch_size = batch_size, shuffle=True)\n",
    "images_only_loader = torch.utils.data.DataLoader(image_only_data, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "sample_image, sample_ann = image_w_ann_data[0]['image'], image_w_ann_data[0]['annotation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def formatForPlot(*args):\n",
    "\toutputs = []\n",
    "\tfor arg in args:\n",
    "\t\tif torch.is_tensor(arg):\n",
    "\t\t\targ =  arg.detach().cpu().numpy()\n",
    "\t\toutputs.append(arg.squeeze())\n",
    "\treturn outputs if len(outputs) > 1 else outputs[0] if len(outputs) > 0 else None\n",
    "\n",
    "def plot_generator(orig_image, orig_ann, fake_ann):\n",
    "\torig_image, orig_ann, fake_ann = formatForPlot(orig_image, orig_ann, fake_ann)\n",
    "\tfig = plt.figure(figsize=(15,5))\n",
    "\tax = fig.subplots(ncols=3)\n",
    "\tax[0].imshow(orig_image.squeeze(), cmap='gray')\n",
    "\tax[1].imshow(orig_ann.squeeze(), cmap='gray')\n",
    "\tax[2].imshow(fake_ann.squeeze(), cmap='gray')\n",
    "\tax[0].set_title(\"image\")\n",
    "\tax[1].set_title(\"annotation\")\n",
    "\tax[1].set_title(\"fake annotation\")\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import __add__\n",
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(Conv2dSamePadding, self).__init__(*args, **kwargs)\n",
    "        self.zero_pad_2d = nn.ZeroPad2d(reduce(__add__,\n",
    "            [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in self.kernel_size[::-1]]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return  self._conv_forward(self.zero_pad_2d(input), self.weight, self.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def init_normal_weights(m, mean=0, std=0.02):\n",
    "\tif isinstance(m, nn.Conv2d):\n",
    "\t\ttorch.nn.init.normal_(m.weight, mean=mean, std=std)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(2, 64, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.conv2 = nn.Conv2d(64, 128, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.batchNorm2 = nn.BatchNorm2d(128)\n",
    "\t\tself.conv3 = nn.Conv2d(128, 256, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.batchNorm3 = nn.BatchNorm2d(256)\n",
    "\t\tself.conv4 = nn.Conv2d(256, 512, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.batchNorm4 = nn.BatchNorm2d(512)\n",
    "\t\tself.conv5 = nn.Conv2d(512, 512, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.batchNorm5 = nn.BatchNorm2d(512)\n",
    "\t\tself.conv6 = nn.Conv2d(512, 1, kernel_size=(4,4), stride=(2,2), padding=\"same\")\n",
    "\t\tself.fc = nn.Linear(512, 1)\n",
    "\t\tfor conv in [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5, self.conv6]:\n",
    "\t\t\tinit_normal_weights(conv)\n",
    "\n",
    "\n",
    "\tdef forward(self, x, y):\n",
    "\t\tz = torch.cat((x, y), dim=1)\n",
    "\t\tz = F.leaky_relu(self.conv1(z), negative_slope=0.2, inplace=True)\n",
    "\t\tz = F.leaky_relu(self.batchNorm2(self.conv2(z)), negative_slope=0.2, inplace=True)\n",
    "\t\tz = F.leaky_relu(self.batchNorm3(self.conv3(z)), negative_slope=0.2, inplace=True)\n",
    "\t\tz = F.leaky_relu(self.batchNorm4(self.conv4(z)), negative_slope=0.2, inplace=True)\n",
    "\t\tz = F.leaky_relu(self.batchNorm5(self.conv5(z)), negative_slope=0.2, inplace=True)\n",
    "\t\tz = self.conv6(z)\n",
    "\t\tz = self.fc(z)\n",
    "\t\treturn torch.sigmoid(z)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "\tdef __init__(self, in_ch, out_ch, batchNorm=True):\n",
    "\t\tsuper(EncoderBlock, self).__init__()\n",
    "\t\tlayers = [nn.Conv2d(in_ch, out_ch, kernel_size=(4,4), stride=(2,2), padding=\"same\")]\n",
    "\t\tif batchNorm:\n",
    "\t\t\tlayers.append(nn.BatchNorm2d(out_ch))\n",
    "\t\tlayers.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\t\tinit_normal_weights(layers[0])\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.layers(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "\tdef __init__(self, in_ch, out_ch, dropout = True):\n",
    "\t\tsuper(DecoderBlock, self).__init__()\n",
    "\t\tlayers = [\n",
    "\t\t\tnn.ConvTranspose2d(in_ch, out_ch, kernel_size=(4,4), stride=(2,2), padding='same'),\n",
    "\t\t\tnn.BatchNorm2d(out_ch)\n",
    "\t\t]\n",
    "\t\tif dropout:\n",
    "\t\t\tlayers.append(nn.Dropout(0.5))\n",
    "\t\tinit_normal_weights(layers[0])\n",
    "\t\tself.layers = nn.Sequential(*layers)\n",
    "\n",
    "\tdef forward(self, x, skip_in):\n",
    "\t\tx = self.layers(x)\n",
    "\t\treturn F.relu(torch.cat((x, skip_in), dim=1))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Generator, self).__init__()\n",
    "\t\tself.e1 = EncoderBlock(1, 64, batchNorm=False)\n",
    "\t\tself.e2 = EncoderBlock(64, 128)\n",
    "\t\tself.e3 = EncoderBlock(128, 256)\n",
    "\t\tself.e4 = EncoderBlock(256, 512)\n",
    "\t\tself.e5 = EncoderBlock(512, 512)\n",
    "\t\tself.e6 = EncoderBlock(512, 512)\n",
    "\t\tself.e7 = EncoderBlock(512, 512)\n",
    "\t\tself.bottleneck = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=(4,4), stride=(2,2), padding='same'),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "\t\t)\n",
    "\t\tinit_normal_weights(self.bottleneck[0])\n",
    "\t\tself.d1 = DecoderBlock(512, 512)\n",
    "\t\tself.d2 = DecoderBlock(512, 512)\n",
    "\t\tself.d3 = DecoderBlock(512, 512)\n",
    "\t\tself.d4 = DecoderBlock(512, 512, dropout=False)\n",
    "\t\tself.d5 = DecoderBlock(512, 256, dropout=False)\n",
    "\t\tself.d6 = DecoderBlock(256, 128, dropout=False)\n",
    "\t\tself.d7 = DecoderBlock(128, 64, dropout=False)\n",
    "\t\tself.output = nn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(64, 1, kernel_size=(4,4), stride=(2,2), padding='same'),\n",
    "\t\t\tnn.Tanh()\n",
    "\t\t)\n",
    "\t\tinit_normal_weights(self.output[0])\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# encoding:\n",
    "\t\te1 = self.e1(x)\n",
    "\t\te2 = self.e2(e1)\n",
    "\t\te3 = self.e3(e2)\n",
    "\t\te4 = self.e4(e3)\n",
    "\t\te5 = self.e5(e4)\n",
    "\t\te6 = self.e6(e5)\n",
    "\t\te7 = self.e7(e6)\n",
    "\n",
    "\t\t# bottleneck:\n",
    "\t\tb = self.bottleneck(e7)\n",
    "\n",
    "\t\t# decoding:\n",
    "\t\td1 = self.d1(b, e7)\n",
    "\t\td2 = self.d2(d1, e6)\n",
    "\t\td3 = self.d3(d2, e5)\n",
    "\t\td4 = self.d4(d3, e4)\n",
    "\t\td5 = self.d5(d4, e3)\n",
    "\t\td6 = self.d6(d5, e2)\n",
    "\t\td7 = self.d7(d6, e1)\n",
    "\t\treturn self.output(d7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class CellGAN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(CellGAN, self).__init__()\n",
    "\t\tself.D = Discriminator()\n",
    "\t\tself.G = Generator()\n",
    "\t\tself.to(device)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.G.eval()\n",
    "\t\treturn self.G(x)\n",
    "\n",
    "\n",
    "\tdef G_loss(self, image):\n",
    "\t\tself.G.train()\n",
    "\t\tself.D.eval()\n",
    "\t\tfake_ann = self.G(image)\n",
    "\t\tD_fake = self.D(image, fake_ann)\n",
    "\t\treturn -torch.mean(torch.log(D_fake + epsilon))\n",
    "\n",
    "\tdef D_loss(self, image, real_ann = None):\n",
    "\t\tself.D.train()\n",
    "\t\tself.G.eval()\n",
    "\t\tfake_ann = self.G(image)\n",
    "\t\tD_fake = self.D(image, fake_ann)\n",
    "\t\tif real_ann is not None:\n",
    "\t\t\tD_real = self.D(image, real_ann)\n",
    "\t\t\treturn -torch.mean(torch.log(D_real + epsilon) + torch.log(1-D_fake + epsilon))\n",
    "\t\telse:\n",
    "\t\t\treturn -torch.mean(torch.log(1-D_fake + epsilon))\n",
    "\n",
    "\tdef run_training(self,epochs: int = 10, G_lr: int = 2e-4, D_lr: int = 2e-4, plot:bool = True):\n",
    "\t\tD_Opt = torch.optim.Adam(params=self.D.parameters(), lr=D_lr, betas=(0.5,0.5))\n",
    "\t\tG_Opt = torch.optim.Adam(params=self.G.parameters(), lr=G_lr, betas=(0.5,0.5))\n",
    "\t\td_losses, g_losses = [], []\n",
    "\t\tfor epoch in range(1, epochs+1):\n",
    "\t\t\timages_only_iter = iter(images_only_loader)\n",
    "\t\t\td_epoch_losses, g_epoch_losses = [], []\n",
    "\t\t\tfor i, batch in enumerate(images_w_ann_loader, 0):\n",
    "\t\t\t\timage, ann = batch['image'].to(device), batch['annotation'].to(device)\n",
    "\t\t\t\td_step_loss, g_step_loss = 0, 0\n",
    "\t\t\t\t# train discriminator:\n",
    "\t\t\t\td_loss = self.D_loss(image, ann)\n",
    "\t\t\t\tD_Opt.zero_grad()\n",
    "\t\t\t\td_loss.backward()\n",
    "\t\t\t\tD_Opt.step()\n",
    "\t\t\t\td_step_loss += d_loss.item() / 2\n",
    "\n",
    "\t\t\t\t# train generator:\n",
    "\t\t\t\tg_loss = self.G_loss(image)\n",
    "\t\t\t\tG_Opt.zero_grad()\n",
    "\t\t\t\tg_loss.backward()\n",
    "\t\t\t\tG_Opt.step()\n",
    "\t\t\t\tg_step_loss += g_loss.item() / 2\n",
    "\n",
    "\t\t\t\t# semi supervised:\n",
    "\t\t\t\tfor _ in range(3):\n",
    "\t\t\t\t\tstep_d_losses, step_g_losses = [],[]\n",
    "\t\t\t\t\timage = next(images_only_iter)\n",
    "\n",
    "\t\t\t\t\t# train discriminator:\n",
    "\t\t\t\t\td_loss = self.D_loss(image)\n",
    "\t\t\t\t\tD_Opt.zero_grad()\n",
    "\t\t\t\t\td_loss.backward()\n",
    "\t\t\t\t\tD_Opt.step()\n",
    "\t\t\t\t\tg_step_loss += d_loss.item() / 6\n",
    "\n",
    "\t\t\t\t\t# train generator:\n",
    "\t\t\t\t\tg_loss = self.G_loss(image)\n",
    "\t\t\t\t\tG_Opt.zero_grad()\n",
    "\t\t\t\t\tg_loss.backward()\n",
    "\t\t\t\t\tG_Opt.step()\n",
    "\t\t\t\t\tg_step_loss += g_loss.item() / 6\n",
    "\t\t\t\td_epoch_losses.append(d_step_loss)\n",
    "\t\t\t\tg_epoch_losses.append(g_step_loss)\n",
    "\n",
    "\t\t\td_losses.append(np.mean(d_epoch_losses))\n",
    "\t\t\tg_losses.append(np.mean(g_epoch_losses))\n",
    "\t\t\tprint(f'epoch [{epoch}/{epochs}],'\n",
    "\t\t\t\t  f' generator loss:{g_losses[epoch-1].round(3)},'\n",
    "\t\t\t\t  f' discriminator loss:{d_losses[epoch-1].round(3)}')\n",
    "\t\t\tif plot:\n",
    "\t\t\t\tself.G.eval()\n",
    "\t\t\t\twith torch.no_grad:\n",
    "\t\t\t\t\tfake_ann = self.G(sample_image)\n",
    "\t\t\t\t\tplot_generator(sample_image, sample_ann, fake_ann)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 520, 704])\n",
      "torch.Size([4, 64, 259, 351])\n",
      "torch.Size([4, 128, 128, 174])\n",
      "torch.Size([4, 256, 63, 86])\n",
      "torch.Size([4, 512, 30, 42])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Got 63 and 62 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_32916/3330459365.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mgan\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCellGAN\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mgan\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_training\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_32916/2432355218.py\u001B[0m in \u001B[0;36mrun_training\u001B[1;34m(self, epochs, G_lr, D_lr, plot)\u001B[0m\n\u001B[0;32m     40\u001B[0m                                 \u001B[0md_step_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mg_step_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m                                 \u001B[1;31m# train discriminator:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m                                 \u001B[0md_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mD_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mann\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m                                 \u001B[0mD_Opt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m                                 \u001B[0md_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_32916/2432355218.py\u001B[0m in \u001B[0;36mD_loss\u001B[1;34m(self, image, real_ann)\u001B[0m\n\u001B[0;32m     21\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mD\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m                 \u001B[0mfake_ann\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mG\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m                 \u001B[0mD_fake\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfake_ann\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mreal_ann\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_32916/441069618.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    117\u001B[0m                 \u001B[0md3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m                 \u001B[0md4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md4\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m                 \u001B[0md5\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md5\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m                 \u001B[0md6\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md6\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m                 \u001B[0md7\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0md7\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md6\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_32916/441069618.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, skip_in)\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mskip_in\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m                 \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m                 \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mskip_in\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     63\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfinalConv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 2. Got 63 and 62 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "gan = CellGAN()\n",
    "gan.run_training()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}